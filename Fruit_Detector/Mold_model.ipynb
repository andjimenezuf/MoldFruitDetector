{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DLI_Header.png\" style=\"width: 200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I'll train a model to recognize fresh and rotten fruits. The dataset comes from [Kaggle](https://www.kaggle.com/sriramr/fruits-fresh-and-rotten-for-classification). The dataset structure is in the `data/fruits` folder. There are 6 categories of fruits: fresh apples, fresh oranges, fresh bananas, rotten apples, rotten oranges, and rotten bananas. This means my model will need an output layer with six neurons to handle the categorization accurately. I'll also compile the model using categorical_crossentropy, since there are more than two categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fruits.png\" style=\"width: 200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ImageNet Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I'll start with a model pretrained on ImageNet. I’ll load the model with the correct weights, set an input shape, and remove the last layers of the model. I’ll keep in mind that images have three dimensions: height, width, and the number of channels. Since these images are in color, there will be three channels for red, green, and blue. The input shape is already provided and must remain unchanged, or the assessment will fail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "base_model = keras.applications.VGG16(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll freeze the base model. This step will help preserve all the learning from the ImageNet dataset during the initial training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Freeze base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Layers to Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it’s time to add layers to the pretrained model. I’ll pay close attention to the final dense layer, ensuring it has the correct number of neurons to classify the different types of fruit accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inputs with correct shape\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# Add pooling layer or flatten layer\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add final dense layer\n",
    "outputs = keras.layers.Dense(6, activation = 'softmax')(x)\n",
    "\n",
    "# Combine inputs and outputs to create model\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,717,766\n",
      "Trainable params: 3,078\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it’s time to compile the model with the appropriate loss and metrics options. Since this is a multi-category classification problem rather than binary, I’ll use a loss function suited for multiple classes, like categorical_crossentropy, to ensure the model can differentiate between the various fruit categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the dataset, I can try augmenting the data, which may enhance the model's performance and help reach the 92% accuracy target. Data augmentation involves creating variations of the training images, such as rotating, flipping, or adjusting brightness, to help the model generalize better. While optional, this step can be especially useful for increasing accuracy when working with limited data. The [Keras ImageDataGenerator class](https://keras.io/api/preprocessing/image/#imagedatagenerator-class) provides useful tools for implementing these augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it’s time to load the training and validation datasets. I’ll select the correct folders and ensure the `target_size` of the images matches the model's input height and width. This alignment is essential for the model to process the images correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1182 images belonging to 6 classes.\n",
      "Found 329 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    " # load and iterate training dataset\n",
    "train_it = datagen.flow_from_directory('data/fruits/train/', \n",
    "                                       target_size=(224, 224), \n",
    "                                       color_mode='rgb', \n",
    "                                       class_mode=\"categorical\"\n",
    "                                      )\n",
    "# load and iterate test dataset\n",
    "valid_it = datagen.flow_from_directory('data/fruits/valid/', \n",
    "                                      target_size=(224, 224), \n",
    "                                      color_mode='rgb', \n",
    "                                      class_mode=\"categorical\"\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it’s time to train the model using the `fit` function with the `train_it` and `valid_it` iterators:\n",
    "\n",
    "- `steps_per_epoch=train_it.samples/train_it.batch_size` ensures the model sees all training samples once per epoch.\n",
    "- `validation_steps=valid_it.samples/valid_it.batch_size` allows all validation data to be used each epoch for evaluation.\n",
    "- `epochs=10` sets the model to go through the full training data 10 times, refining its parameters with each pass.\n",
    "\n",
    "These settings help ensure thorough learning from both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 09:35:11.106900: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-11-03 09:35:11.111471: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/36 [==============================] - ETA: 0s - loss: 2.9957 - accuracy: 0.4780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 09:36:11.989053: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 78s 2s/step - loss: 2.9957 - accuracy: 0.4780 - val_loss: 1.7096 - val_accuracy: 0.6505\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 78s 2s/step - loss: 0.9141 - accuracy: 0.7707 - val_loss: 0.8062 - val_accuracy: 0.8237\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 78s 2s/step - loss: 0.4307 - accuracy: 0.8680 - val_loss: 0.5661 - val_accuracy: 0.8541\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 78s 2s/step - loss: 0.2447 - accuracy: 0.9213 - val_loss: 0.4307 - val_accuracy: 0.8906\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 79s 2s/step - loss: 0.1479 - accuracy: 0.9484 - val_loss: 0.4174 - val_accuracy: 0.8815\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 78s 2s/step - loss: 0.1087 - accuracy: 0.9670 - val_loss: 0.3503 - val_accuracy: 0.8997\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 79s 2s/step - loss: 0.0768 - accuracy: 0.9721 - val_loss: 0.4371 - val_accuracy: 0.8875\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 78s 2s/step - loss: 0.0582 - accuracy: 0.9831 - val_loss: 0.3180 - val_accuracy: 0.9119\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 79s 2s/step - loss: 0.0410 - accuracy: 0.9873 - val_loss: 0.3030 - val_accuracy: 0.9149\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 76s 2s/step - loss: 0.0301 - accuracy: 0.9932 - val_loss: 0.3170 - val_accuracy: 0.9119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176f09610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_it,\n",
    "          validation_data=valid_it,\n",
    "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
    "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze Model for Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial goal is to reach 92% validation accuracy. If I haven’t achieved this yet, I’ll proceed by unfreezing the model layers and fine-tuning it with a very low learning rate. This allows for small, targeted adjustments to further improve performance without significantly altering the pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Compile the model with a low learning rate\n",
    "# Using legacy RMSprop optimizer for improved performance on ARM Macs\n",
    "model.compile(optimizer=keras.optimizers.legacy.RMSprop(learning_rate=0.00001),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 09:51:53.243365: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/36 [==============================] - ETA: 0s - loss: 0.1286 - accuracy: 0.9670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 09:55:23.065124: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 226s 6s/step - loss: 0.1286 - accuracy: 0.9670 - val_loss: 0.2351 - val_accuracy: 0.9422\n",
      "Epoch 2/2\n",
      "36/36 [==============================] - 221s 6s/step - loss: 0.0184 - accuracy: 0.9924 - val_loss: 0.2342 - val_accuracy: 0.9544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x319803310>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_it,\n",
    "          validation_data=valid_it,\n",
    "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
    "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
    "          epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I’m satisfied with my validation accuracy, I’ll evaluate the model using the `evaluate` function. This function returns a tuple where the first value is the loss, and the second value is the accuracy. To pass, my model needs an accuracy of 92% or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 09:59:27.275182: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 16s 2s/step - loss: 0.2342 - accuracy: 0.9544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23421694338321686, 0.954407274723053]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_it, steps=valid_it.samples/valid_it.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Summary:\n",
    "\n",
    "In this project, I developed a deep learning model to classify fresh and rotten fruits into six categories: fresh apples, fresh oranges, fresh bananas, rotten apples, rotten oranges, and rotten bananas. I used a pretrained model with transfer learning to leverage existing knowledge from ImageNet and then fine-tuned the model to improve performance on this specific dataset. Data augmentation and a low learning rate were applied during fine-tuning to prevent overfitting and to make small, effective adjustments to the model weights.\n",
    "\n",
    "### Final Accuracy and Interpretation:\n",
    "\n",
    "The model achieved a validation accuracy of **95.44%**, surpassing the target of 92%. This high accuracy indicates that the model is well-trained and can reliably differentiate between fresh and rotten fruits in the specified categories. The use of transfer learning and fine-tuning proved to be effective in adapting a general-purpose model to a specialized classification task with high accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
